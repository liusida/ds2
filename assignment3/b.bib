
@article{ha_world_2018,
	title = {World {Models}},
	url = {http://arxiv.org/abs/1803.10122},
	doi = {10.5281/zenodo.1207631},
	abstract = {We explore building generative neural network models of popular reinforcement learning environments. Our world model can be trained quickly in an unsupervised manner to learn a compressed spatial and temporal representation of the environment. By using features extracted from the world model as inputs to an agent, we can train a very compact and simple policy that can solve the required task. We can even train our agent entirely inside of its own hallucinated dream generated by its world model, and transfer this policy back into the actual environment. An interactive version of this paper is available at https://worldmodels.github.io/},
	urldate = {2021-02-15},
	journal = {arXiv:1803.10122 [cs, stat]},
	author = {Ha, David and Schmidhuber, Jürgen},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.10122},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/liusida/Zotero/storage/3KXJFVU3/Ha and Schmidhuber - 2018 - World Models.pdf:application/pdf;arXiv.org Snapshot:/home/liusida/Zotero/storage/7IQBU8BI/1803.html:text/html}
}

@article{wang_survey_2020,
	title = {A {Survey} on {Bayesian} {Deep} {Learning}},
	volume = {53},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3409383},
	doi = {10.1145/3409383},
	abstract = {A comprehensive artificial intelligence system needs to not only perceive the environment with different “senses” (e.g., seeing and hearing) but also infer the world’s conditional (or even causal) relations and corresponding uncertainty. The past decade has seen major advances in many perception tasks, such as visual object recognition and speech recognition, using deep learning models. For higher-level inference, however, probabilistic graphical models with their Bayesian nature are still more powerful and flexible. In recent years, Bayesian deep learning has emerged as a unified probabilistic framework to tightly integrate deep learning and Bayesian models.1 In this general framework, the perception of text or images using deep learning can boost the performance of higher-level inference and, in turn, the feedback from the inference process is able to enhance the perception of text or images. This survey provides a comprehensive introduction to Bayesian deep learning and reviews its recent applications on recommender systems, topic models, control, and so on. We also discuss the relationship and differences between Bayesian deep learning and other related topics, such as Bayesian treatment of neural networks.},
	number = {5},
	urldate = {2021-03-10},
	journal = {ACM Computing Surveys},
	author = {Wang, Hao and Yeung, Dit-Yan},
	month = sep,
	year = {2020},
	keywords = {Bayesian networks, Deep learning, generative models, probabilistic graphical models},
	pages = {108:1--108:37},
	file = {Full Text PDF:/home/liusida/Zotero/storage/4DI583HE/Wang and Yeung - 2020 - A Survey on Bayesian Deep Learning.pdf:application/pdf}
}

@article{real_regularized_2019,
	title = {Regularized {Evolution} for {Image} {Classifier} {Architecture} {Search}},
	url = {http://arxiv.org/abs/1802.01548},
	abstract = {The effort devoted to hand-crafting neural network image classifiers has motivated the use of architecture search to discover them automatically. Although evolutionary algorithms have been repeatedly applied to neural network topologies, the image classifiers thus discovered have remained inferior to human-crafted ones. Here, we evolve an image classifier---AmoebaNet-A---that surpasses hand-designs for the first time. To do this, we modify the tournament selection evolutionary algorithm by introducing an age property to favor the younger genotypes. Matching size, AmoebaNet-A has comparable accuracy to current state-of-the-art ImageNet models discovered with more complex architecture-search methods. Scaled to larger size, AmoebaNet-A sets a new state-of-the-art 83.9\% / 96.6\% top-5 ImageNet accuracy. In a controlled comparison against a well known reinforcement learning algorithm, we give evidence that evolution can obtain results faster with the same hardware, especially at the earlier stages of the search. This is relevant when fewer compute resources are available. Evolution is, thus, a simple method to effectively discover high-quality architectures.},
	urldate = {2021-03-10},
	journal = {arXiv:1802.01548 [cs]},
	author = {Real, Esteban and Aggarwal, Alok and Huang, Yanping and Le, Quoc V.},
	month = feb,
	year = {2019},
	note = {arXiv: 1802.01548},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Neural and Evolutionary Computing, I.2.6, I.5.1, I.5.2},
	annote = {Comment: Accepted for publication at AAAI 2019, the Thirty-Third AAAI Conference on Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/liusida/Zotero/storage/MR5XMYLP/Real et al. - 2019 - Regularized Evolution for Image Classifier Archite.pdf:application/pdf;arXiv.org Snapshot:/home/liusida/Zotero/storage/ALBBIDPS/1802.html:text/html}
}
